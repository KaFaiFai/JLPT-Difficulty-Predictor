{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyrus/virtualenv/text/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from model import BERTClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df_path):\n",
    "        self.df = pd.read_csv(df_path, index_col=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[str, int]:\n",
    "        sentence = self.df[\"Sentence\"][index]\n",
    "        level = self.df[\"Level\"][index]\n",
    "        label = self.level2label(level)\n",
    "\n",
    "        return sentence, label\n",
    "\n",
    "    @classmethod\n",
    "    def level2label(cls, level):\n",
    "        return {\"N1\": 0, \"N2\": 1, \"N3\": 2, \"N4\": 3, \"N5\": 4}[level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1000\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_SCALE = 0.1\n",
    "LOAD_FROM = None\n",
    "DATA_ROOT = r\"util/jlpt_sentences.csv\"\n",
    "NUM_CLASS = 5\n",
    "EXP_FOLDER = \"exp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "dataset = TextDataset(DATA_ROOT)\n",
    "# sub_dataset = Subset(\n",
    "#     dataset, np.linspace(0, len(dataset), num=50, endpoint=False, dtype=int)\n",
    "# )\n",
    "data_loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassification(num_class=NUM_CLASS).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\")  # to get average easily\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000]\n",
      "[Batch    1/216] Loss: 1.2500 Labels: [2, 4, 1, 3, 1, 2, 0, 3, 3, 2, 2, 1, 2, 4, 2, 3]\n",
      "[Batch   51/216] Loss: 1.3261 Labels: [2, 2, 3, 0, 1, 2, 3, 4, 4, 2, 1, 3, 0, 2, 3, 3]\n",
      "[Batch  101/216] Loss: 1.2542 Labels: [3, 0, 0, 3, 4, 2, 0, 2, 3, 2, 3, 3, 1, 0, 3, 4]\n",
      "[Batch  151/216] Loss: 1.2620 Labels: [3, 1, 2, 2, 0, 2, 4, 0, 3, 2, 4, 1, 3, 3, 1, 2]\n",
      "[Batch  201/216] Loss: 1.4521 Labels: [4, 2, 2, 3, 3, 3, 3, 1, 2, 2, 4, 4, 3, 0, 2, 3]\n",
      "Total loss: 1.3230\n",
      "Epoch [1/1000]\n",
      "[Batch    1/216] Loss: 1.0162 Labels: [1, 2, 3, 3, 3, 2, 2, 4, 1, 2, 2, 2, 4, 3, 2, 3]\n",
      "[Batch   51/216] Loss: 1.2939 Labels: [1, 4, 2, 2, 3, 4, 4, 1, 0, 4, 2, 4, 2, 3, 3, 2]\n",
      "[Batch  101/216] Loss: 1.4404 Labels: [3, 2, 1, 0, 2, 2, 3, 0, 4, 4, 2, 2, 0, 4, 4, 2]\n",
      "[Batch  151/216] Loss: 1.0762 Labels: [3, 3, 2, 2, 3, 2, 2, 3, 1, 1, 4, 2, 4, 2, 1, 1]\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_334591/1281947199.py\", line 8, in <module>\n",
      "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2577, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2663, in _call_one\n",
      "    return self.batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2854, in batch_encode_plus\n",
      "    return self._batch_encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 733, in _batch_encode_plus\n",
      "    first_ids = get_input_ids(ids)\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 700, in get_input_ids\n",
      "    tokens = self.tokenize(text, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils.py\", line 499, in tokenize\n",
      "    str(t): t for t in self.all_special_tokens_extended if isinstance(t, AddedToken)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 1300, in all_special_tokens_extended\n",
      "    set_attr = self.special_tokens_map_extended\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line -1, in special_tokens_map_extended\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1087, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 969, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/cyrus/virtualenv/text/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "    total_loss = 0\n",
    "    all_truths = []\n",
    "    all_outputs = []\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (sentences, labels) in enumerate(data_loader):\n",
    "        inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "        labels = torch.LongTensor(labels).to(DEVICE)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(\n",
    "                f\"[Batch {batch_idx+1:4d}/{len(data_loader)}]\"\n",
    "                f\" Loss: {loss.item()/BATCH_SIZE:.4f}\"\n",
    "                f\" Labels: {labels.tolist()}\"\n",
    "            )\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Total loss: {total_loss/len(dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epoch    1| Loss: 1.6502\n",
    "Epoch   51| Loss: 0.5745\n",
    "Epoch  101| Loss: 0.2626\n",
    "Epoch  151| Loss: 0.1694\n",
    "Epoch  201| Loss: 0.1005\n",
    "Epoch  251| Loss: 0.0651\n",
    "Epoch  301| Loss: 0.0441\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
