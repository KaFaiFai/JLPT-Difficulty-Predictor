{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect difficulty of English text and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyrus/virtualenv/text/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertModel\n",
    "\n",
    "from models.attention import SimpleAttention\n",
    "from models.attention2 import SimpleAttention2\n",
    "from dataset.english_cefr_dataset import EnglishCEFRDataset\n",
    "from util.metrics import ClassificationMetrics\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 10\n",
    "LOAD_FROM = None\n",
    "DATA_ROOT = Path(\"training_data\")\n",
    "NUM_CLASS = 6\n",
    "EXP_FOLDER = Path(\"exp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EnglishCEFRDataset(DATA_ROOT / \"cefr_leveled_texts.csv\")\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.7, 0.1, 0.2])\n",
    "\n",
    "# train_dataset = Subset(train_dataset, np.arange(500))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_dataset = Subset(val_dataset, np.arange(20))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = SimpleAttention2(NUM_CLASS, vocab_size=len(tokenizer)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\")  # to get average easily\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10]\n",
      "[Batch    0/6223] Loss: 1.7855\n",
      "[Batch  500/6223] Loss: 1.8699\n",
      "[Batch 1000/6223] Loss: 1.3012\n",
      "[Batch 1500/6223] Loss: 1.7158\n",
      "[Batch 2000/6223] Loss: 1.9168\n",
      "[Batch 2500/6223] Loss: 0.9582\n",
      "[Batch 3000/6223] Loss: 1.0453\n",
      "[Batch 3500/6223] Loss: 1.6833\n",
      "[Batch 4000/6223] Loss: 1.8783\n",
      "[Batch 4500/6223] Loss: 2.0783\n",
      "[Batch 5000/6223] Loss: 1.0026\n",
      "[Batch 5500/6223] Loss: 0.8255\n",
      "[Batch 6000/6223] Loss: 1.2041\n",
      "Total loss: 1.2985\n",
      "Accuracy: 44.04% | Precision: 0.4748\n",
      "Recall:   0.4447 | F1 score:  0.4394\n",
      "\n",
      "Epoch [1/10]\n",
      "[Batch    0/6223] Loss: 1.4124\n",
      "[Batch  500/6223] Loss: 0.9822\n",
      "[Batch 1000/6223] Loss: 1.2842\n",
      "[Batch 1500/6223] Loss: 1.0720\n",
      "[Batch 2000/6223] Loss: 0.5906\n",
      "[Batch 2500/6223] Loss: 1.2220\n",
      "[Batch 3000/6223] Loss: 1.3089\n",
      "[Batch 3500/6223] Loss: 1.1140\n",
      "[Batch 4000/6223] Loss: 1.1137\n",
      "[Batch 4500/6223] Loss: 1.5354\n",
      "[Batch 5000/6223] Loss: 1.3278\n",
      "[Batch 5500/6223] Loss: 0.5445\n",
      "[Batch 6000/6223] Loss: 1.3003\n",
      "Total loss: 1.1760\n",
      "Accuracy: 50.48% | Precision: 0.5340\n",
      "Recall:   0.5269 | F1 score:  0.5110\n",
      "\n",
      "Epoch [2/10]\n",
      "[Batch    0/6223] Loss: 1.0486\n",
      "[Batch  500/6223] Loss: 0.7984\n",
      "[Batch 1000/6223] Loss: 0.6159\n",
      "[Batch 1500/6223] Loss: 0.2215\n",
      "[Batch 2000/6223] Loss: 0.5179\n",
      "[Batch 2500/6223] Loss: 0.9829\n",
      "[Batch 3000/6223] Loss: 1.5703\n",
      "[Batch 3500/6223] Loss: 0.3493\n",
      "[Batch 4000/6223] Loss: 0.8038\n",
      "[Batch 4500/6223] Loss: 0.3468\n",
      "[Batch 5000/6223] Loss: 0.5395\n",
      "[Batch 5500/6223] Loss: 0.4714\n",
      "[Batch 6000/6223] Loss: 1.1120\n",
      "Total loss: 1.2332\n",
      "Accuracy: 55.57% | Precision: 0.5746\n",
      "Recall:   0.5593 | F1 score:  0.5629\n",
      "\n",
      "Epoch [3/10]\n",
      "[Batch    0/6223] Loss: 0.4140\n",
      "[Batch  500/6223] Loss: 0.1253\n",
      "[Batch 1000/6223] Loss: 0.1006\n",
      "[Batch 1500/6223] Loss: 0.1475\n",
      "[Batch 2000/6223] Loss: 0.0125\n",
      "[Batch 2500/6223] Loss: 0.9550\n",
      "[Batch 3000/6223] Loss: 0.0913\n",
      "[Batch 3500/6223] Loss: 0.7232\n",
      "[Batch 4000/6223] Loss: 0.5594\n",
      "[Batch 4500/6223] Loss: 0.3969\n",
      "[Batch 5000/6223] Loss: 0.5832\n",
      "[Batch 5500/6223] Loss: 0.5358\n",
      "[Batch 6000/6223] Loss: 0.3194\n",
      "Total loss: 1.5797\n",
      "Accuracy: 55.29% | Precision: 0.5764\n",
      "Recall:   0.5520 | F1 score:  0.5590\n",
      "\n",
      "Epoch [4/10]\n",
      "[Batch    0/6223] Loss: 0.2977\n",
      "[Batch  500/6223] Loss: 0.0841\n",
      "[Batch 1000/6223] Loss: 0.3210\n",
      "[Batch 1500/6223] Loss: 0.0055\n",
      "[Batch 2000/6223] Loss: 0.1166\n",
      "[Batch 2500/6223] Loss: 1.3578\n",
      "[Batch 3000/6223] Loss: 0.1867\n",
      "[Batch 3500/6223] Loss: 0.5412\n",
      "[Batch 4000/6223] Loss: 0.1456\n",
      "[Batch 4500/6223] Loss: 0.4630\n",
      "[Batch 5000/6223] Loss: 0.0056\n",
      "[Batch 5500/6223] Loss: 1.5588\n",
      "[Batch 6000/6223] Loss: 0.1529\n",
      "Total loss: 2.0170\n",
      "Accuracy: 55.74% | Precision: 0.5685\n",
      "Recall:   0.5618 | F1 score:  0.5632\n",
      "\n",
      "Epoch [5/10]\n",
      "[Batch    0/6223] Loss: 0.0175\n",
      "[Batch  500/6223] Loss: 0.0185\n",
      "[Batch 1000/6223] Loss: 0.0000\n",
      "[Batch 1500/6223] Loss: 0.0195\n",
      "[Batch 2000/6223] Loss: 0.0150\n",
      "[Batch 2500/6223] Loss: 0.0082\n",
      "[Batch 3000/6223] Loss: 0.0504\n",
      "[Batch 3500/6223] Loss: 0.3689\n",
      "[Batch 4000/6223] Loss: 0.0001\n",
      "[Batch 4500/6223] Loss: 0.0002\n",
      "[Batch 5000/6223] Loss: 0.0027\n",
      "[Batch 5500/6223] Loss: 1.1742\n",
      "[Batch 6000/6223] Loss: 0.0730\n",
      "Total loss: 2.5005\n",
      "Accuracy: 55.82% | Precision: 0.5690\n",
      "Recall:   0.5637 | F1 score:  0.5642\n",
      "\n",
      "Epoch [6/10]\n",
      "[Batch    0/6223] Loss: 0.0039\n",
      "[Batch  500/6223] Loss: 0.1597\n",
      "[Batch 1000/6223] Loss: 0.0010\n",
      "[Batch 1500/6223] Loss: 0.0003\n",
      "[Batch 2000/6223] Loss: 0.0019\n",
      "[Batch 2500/6223] Loss: 0.0017\n",
      "[Batch 3000/6223] Loss: 0.0050\n",
      "[Batch 3500/6223] Loss: 0.6774\n",
      "[Batch 4000/6223] Loss: 0.1428\n",
      "[Batch 4500/6223] Loss: 0.0083\n",
      "[Batch 5000/6223] Loss: 0.1172\n",
      "[Batch 5500/6223] Loss: 0.0012\n",
      "[Batch 6000/6223] Loss: 0.0032\n",
      "Total loss: 3.1089\n",
      "Accuracy: 55.65% | Precision: 0.5756\n",
      "Recall:   0.5537 | F1 score:  0.5609\n",
      "\n",
      "Epoch [7/10]\n",
      "[Batch    0/6223] Loss: 0.0122\n",
      "[Batch  500/6223] Loss: 0.0099\n",
      "[Batch 1000/6223] Loss: 0.0192\n",
      "[Batch 1500/6223] Loss: 0.0011\n",
      "[Batch 2000/6223] Loss: 0.0019\n",
      "[Batch 2500/6223] Loss: 0.0078\n",
      "[Batch 3000/6223] Loss: 0.0250\n",
      "[Batch 3500/6223] Loss: 0.0000\n",
      "[Batch 4000/6223] Loss: 0.0017\n",
      "[Batch 4500/6223] Loss: 0.0000\n",
      "[Batch 5000/6223] Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/virtualenv/text/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/virtualenv/text/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (sentences, labels) in enumerate(train_loader):\n",
    "        inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "        labels = torch.LongTensor(labels).to(DEVICE)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 500 == 0:\n",
    "            print(f\"[Batch {batch_idx:4d}/{len(train_loader)}] Loss: {loss.item()/BATCH_SIZE:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_truths = []\n",
    "    val_outputs = []\n",
    "    for batch_idx, (sentences, labels) in enumerate(val_loader):\n",
    "        inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "        labels = torch.LongTensor(labels).to(DEVICE)\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_truths += labels.detach().cpu().tolist()\n",
    "        val_outputs.append(outputs.detach().cpu())\n",
    "\n",
    "    print(f\"Total loss: {val_loss/len(val_dataset):.4f}\")\n",
    "\n",
    "    val_outputs = torch.cat(val_outputs)  # from list of tensor to numpy array\n",
    "    metrics = ClassificationMetrics(val_truths, val_outputs)\n",
    "    metrics.print_report()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 51, 51])\n",
      "tensor(4., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([1, 0, 5, 4], device='cuda:0')\n",
      "          [CLS]         George             is          going             to           take              a          spare           tire            and            gas              ,           just             in           case           they            run            out          [SEP]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]\n",
      "         0.1068         0.0831         0.0400         0.0177         0.0678         0.0149         0.0483         0.0232         0.0320         0.0077         0.0174         0.0864         0.0338         0.0170         0.0278         0.0061         0.0737         0.0618         0.2344         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000\n",
      "          [CLS]             He           will           move           into            his            car          [SEP]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]\n",
      "         0.2563         0.0103         0.0626         0.0316         0.0414         0.0184         0.0585         0.5210         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000\n",
      "          [CLS]            But              ,        instead             of           this          being            the        counter              -  revolutionary              ,             or           post              -  revolutionary              ,           move             of              a           free              -         market          rebel              ,              K          ##cho            may           have           been       selected             as            the     acceptable           face             of              a         regime              a            ##c          ##qui           ##es         ##cing             to            the     inevitable           lure             of            the       internet          [SEP]\n",
      "         0.0324         0.0019         0.0401         0.0216         0.0250         0.0065         0.0213         0.0479         0.0126         0.0016         0.0268         0.0362         0.0117         0.0064         0.0007         0.0277         0.0452         0.0034         0.0186         0.0108         0.0046         0.0006         0.0115         0.0158         0.0371         0.0108         0.0146         0.0095         0.0024         0.0150         0.0263         0.0061         0.0262         0.0281         0.0089         0.0243         0.0159         0.0148         0.0122         0.0183         0.0220         0.0227         0.0082         0.0228         0.0258         0.0114         0.0222         0.0354         0.0291         0.0173         0.0818\n",
      "          [CLS]           That        offense            was             Bo        ##stick              '              s          third        drunken        driving         arrest             in              a         little           more           than           year          [SEP]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]          [PAD]\n",
      "         0.1082         0.0149         0.0511         0.0332         0.1180         0.1085         0.0701         0.0157         0.0685         0.0143         0.0096         0.0339         0.0162         0.0541         0.0372         0.0074         0.0300         0.0151         0.1942         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000         0.0000\n"
     ]
    }
   ],
   "source": [
    "batch_idx, (sentences, labels) = next(enumerate(train_loader))\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "tokens_list = [tokenizer.convert_ids_to_tokens(ids) for ids in inputs[\"input_ids\"]]\n",
    "\n",
    "model.eval()\n",
    "_, attention = model.get_attention_output(**inputs)\n",
    "outputs = model(**inputs)\n",
    "predictions = torch.argmax(outputs, axis=1)\n",
    "\n",
    "cls_attn = attention[:, 0, :]\n",
    "print(attention.shape)\n",
    "print(cls_attn.sum())\n",
    "print(predictions)\n",
    "\n",
    "for tokens, attn in zip(tokens_list, cls_attn):\n",
    "    for t in tokens:\n",
    "        print(f\"{t:>15}\", end=\"\")\n",
    "    print()\n",
    "    for a in attn.tolist():\n",
    "        print(f\"{a:15.4f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fprop = fm.FontProperties(fname=\"resource/NotoSansJP-Regular.ttf\")\n",
    "\n",
    "i = 1\n",
    "max_length = 12\n",
    "\n",
    "tokens: list[str] = tokens_list[i]\n",
    "attn = cls_attn[i].tolist()\n",
    "label = EnglishCEFRDataset.target2level(labels[i].item())\n",
    "prediction = EnglishCEFRDataset.target2level(predictions[i].item())\n",
    "\n",
    "words = []\n",
    "values = []\n",
    "for t, a in zip(tokens, attn):\n",
    "    if t == \"[PAD]\":\n",
    "        break\n",
    "    if t.startswith(\"##\"):\n",
    "        # combine subwords\n",
    "        words[-1] = words[-1] + t[2:]\n",
    "        values[-1] += a\n",
    "    else:\n",
    "        words.append(t)\n",
    "        values.append(a)\n",
    "\n",
    "words = [\"LABEL:\", \"PRED:\"] + words\n",
    "attn_strs = [label, prediction] + [f\"{a:.4f}\" for a in values]\n",
    "colors = [\"w\", \"w\"] + [str(1 - a) for a in values]\n",
    "\n",
    "\n",
    "def plot_pairs(plt, words, values, colors, max_length=max_length):\n",
    "    seq_length = len(words)\n",
    "    if seq_length < max_length:\n",
    "        words += [\"\"] * (max_length - seq_length)\n",
    "        values += [\"\"] * (max_length - seq_length)\n",
    "        colors += [\"w\"] * (max_length - seq_length)\n",
    "    plt.axis(\"off\")\n",
    "    table = plt.table(cellText=[values], cellColours=[colors], colLabels=words, loc=\"center\")\n",
    "    for cell in table._cells:\n",
    "        table._cells[cell].set_text_props(fontproperties=fprop)\n",
    "    table.scale(1, 4)\n",
    "\n",
    "\n",
    "num_lines = math.ceil(len(words) / max_length)\n",
    "fig, ax = plt.subplots(num_lines, 1, figsize=(20, 2 * num_lines))\n",
    "if num_lines == 1:\n",
    "    plot_pairs(ax, words, attn_strs, colors)\n",
    "else:\n",
    "    for i in range(num_lines):\n",
    "        s, e = i * max_length, (i + 1) * max_length\n",
    "        plot_pairs(ax[i], words[s:e], attn_strs[s:e], colors[s:e])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]], device='cuda:0')\n",
      "['[CLS]', 'Rep', '##lace', 'me', 'by', 'any', 'text', 'you', \"'\", 'd', 'like', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "['[CLS]', 'Some', 'weights', 'of', 'the', 'model', 'check', '##point', 'at', 'be', '##rt', '-', 'base', '-', 'case', '##d', 'were', 'not', 'used', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "line = \"Replace me by any text you'd like.\"\n",
    "line2 = \"Some weights of the model checkpoint at bert-base-cased were not used\"\n",
    "inputs = tokenizer([line, line2], return_tensors=\"pt\", padding=\"max_length\").to(DEVICE)\n",
    "print(inputs.keys())\n",
    "print(inputs[\"attention_mask\"] == 0)\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0]))\n",
    "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][1]))\n",
    "\n",
    "out = model(**inputs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
